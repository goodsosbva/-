{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-d2931f37162f>:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lara Croft Tomb Raider: The Cradle of Life</td>\n",
       "      <td>0.88</td>\n",
       "      <td>[Action, Adventure, Fantasy, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the Bedroom</td>\n",
       "      <td>0.87</td>\n",
       "      <td>[Drama, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Requiem</td>\n",
       "      <td>0.87</td>\n",
       "      <td>[Action, Horror, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shattered</td>\n",
       "      <td>0.86</td>\n",
       "      <td>[Mystery, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die Hard: With a Vengeance</td>\n",
       "      <td>0.85</td>\n",
       "      <td>[Action, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Flintstones</td>\n",
       "      <td>0.83</td>\n",
       "      <td>[Fantasy, Comedy, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To End All Wars</td>\n",
       "      <td>0.83</td>\n",
       "      <td>[Action, Comedy, Drama, History]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Star Trek VI: The Undiscovered Country</td>\n",
       "      <td>0.82</td>\n",
       "      <td>[Science Fiction, Action, Adventure, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Body of Evidence</td>\n",
       "      <td>0.78</td>\n",
       "      <td>[Drama, Thriller, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ludwig</td>\n",
       "      <td>0.78</td>\n",
       "      <td>[Drama, History]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title Correlation  \\\n",
       "0  Lara Croft Tomb Raider: The Cradle of Life        0.88   \n",
       "1                              In the Bedroom        0.87   \n",
       "2                                     Requiem        0.87   \n",
       "3                                   Shattered        0.86   \n",
       "4                  Die Hard: With a Vengeance        0.85   \n",
       "5                             The Flintstones        0.83   \n",
       "6                             To End All Wars        0.83   \n",
       "7      Star Trek VI: The Undiscovered Country        0.82   \n",
       "8                            Body of Evidence        0.78   \n",
       "9                                      Ludwig        0.78   \n",
       "\n",
       "                                            Genre  \n",
       "0          [Action, Adventure, Fantasy, Thriller]  \n",
       "1                               [Drama, Thriller]  \n",
       "2                      [Action, Horror, Thriller]  \n",
       "3                             [Mystery, Thriller]  \n",
       "4                              [Action, Thriller]  \n",
       "5                       [Fantasy, Comedy, Family]  \n",
       "6                [Action, Comedy, Drama, History]  \n",
       "7  [Science Fiction, Action, Adventure, Thriller]  \n",
       "8                      [Drama, Thriller, Romance]  \n",
       "9                                [Drama, History]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "meta = pd.read_csv('C:/Users/hs/Desktop/khs/movies_metadata.csv/movies_metadata.csv',dtype= 'unicode' )\n",
    "meta = meta[['id', 'original_title', 'original_language', 'genres']]\n",
    "meta = meta.rename(columns={'id':'movieId'})\n",
    "meta = meta[meta['original_language'] == 'en']\n",
    "meta.head()\n",
    "\n",
    "ratings = pd.read_csv('C:/Users/hs/Desktop/khs/ratings_small.csv/ratings_small.csv')\n",
    "ratings = ratings[['userId', 'movieId', 'rating']]\n",
    "\n",
    "ratings.head()\n",
    "ratings.describe()\n",
    "\n",
    "meta.movieId = pd.to_numeric(meta.movieId, errors='coerce')\n",
    "ratings.movieId = pd.to_numeric(ratings.movieId, errors='coerce')\n",
    "\n",
    "\n",
    "def parse_genres(genres_str):\n",
    "    genres = json.loads(genres_str.replace('\\'', '\"'))\n",
    "\n",
    "    genres_list = []\n",
    "    for g in genres:\n",
    "        genres_list.append(g['name'])\n",
    "\n",
    "    return genres_list\n",
    "\n",
    "\n",
    "meta['genres'] = meta['genres'].apply(parse_genres)\n",
    "\n",
    "meta.head()\n",
    "\n",
    "data = pd.merge(ratings, meta, on='movieId', how='inner')\n",
    "\n",
    "data.head()\n",
    "\n",
    "\n",
    "matrix = data.pivot_table(index='userId', columns='original_title', values='rating')\n",
    "\n",
    "matrix.head(20)\n",
    "\n",
    "GENRE_WEIGHT = 0.1\n",
    "\n",
    "def pearsonR(s1, s2):\n",
    "    s1_c = s1 - s1.mean()\n",
    "    s2_c = s2 - s2.mean()\n",
    "    \n",
    "    \n",
    "    return np.sum(s1_c * s2_c) / np.sqrt(np.sum(s1_c ** 2) * np.sum(s2_c ** 2))\n",
    "    \n",
    "\n",
    "\n",
    "def recommend(input_movie, matrix, n, similar_genre=True):\n",
    "    input_genres = meta[meta['original_title'] == input_movie]['genres'].iloc(0)[0]\n",
    "\n",
    "    result = []\n",
    "    for title in matrix.columns:\n",
    "        if title == input_movie:\n",
    "            continue\n",
    "\n",
    "        # rating comparison\n",
    "        cor = pearsonR(matrix[input_movie], matrix[title])\n",
    "\n",
    "        # genre comparison\n",
    "        if similar_genre and len(input_genres) > 0:\n",
    "            temp_genres = meta[meta['original_title'] == title]['genres'].iloc(0)[0]\n",
    "\n",
    "            same_count = np.sum(np.isin(input_genres, temp_genres))\n",
    "            cor += (GENRE_WEIGHT * same_count)\n",
    "\n",
    "        if np.isnan(cor):\n",
    "            continue\n",
    "        else:\n",
    "            result.append((title, '{:.2f}'.format(cor), temp_genres))\n",
    "\n",
    "    result.sort(key=lambda r: r[1], reverse=True)\n",
    "\n",
    "    return result[:n]\n",
    "\n",
    "recommend_result = recommend('Topaz', matrix, 10, similar_genre=True)\n",
    "\n",
    "pd.DataFrame(recommend_result, columns = ['Title', 'Correlation', 'Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(\"C:/Users/hs/Desktop/hand_write/mnist_dataset.csv\", \"r\")\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "from  matplotlib import pyplot \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_values = data_list[2].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "pyplot.imshow(image_array, cmap=\"Greys\", interpolation=\"None\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.27011765 0.91070588\n",
      " 0.16141176 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.25070588 0.32447059\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.47588235 0.70882353 0.16141176 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.49917647 0.64282353 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01776471\n",
      " 0.604      0.82529412 0.16529412 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.86411765 0.64282353 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.11482353 0.99611765 0.63894118\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.87188235 0.64282353\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.72047059 0.99611765 0.49529412 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.18858824 0.96117647 0.64282353 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.77870588\n",
      " 0.99611765 0.22741176 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.47588235\n",
      " 0.99611765 0.64282353 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.09929412 0.90682353 0.99611765 0.12258824\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.62729412 0.99611765 0.47588235\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.64282353 0.99611765 0.84858824 0.07211765 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.62729412 0.99611765 0.27011765 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.06435294 0.34388235 0.70105882 0.97282353 0.99611765\n",
      " 0.36329412 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.62729412\n",
      " 0.99611765 0.34       0.01       0.01       0.01       0.19247059\n",
      " 0.20023529 0.46035294 0.56905882 0.59235294 0.94564706 0.95341176\n",
      " 0.91847059 0.70494118 0.94564706 0.98835294 0.16529412 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.59235294 0.99223529 0.93011765\n",
      " 0.81364706 0.81364706 0.81364706 0.99223529 0.99611765 0.98058824\n",
      " 0.94176471 0.77870588 0.56517647 0.36329412 0.11870588 0.02941176\n",
      " 0.91458824 0.98058824 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.472      0.69717647 0.69717647 0.69717647\n",
      " 0.69717647 0.69717647 0.39047059 0.22741176 0.01       0.01\n",
      " 0.01       0.01       0.01       0.406      0.99611765 0.86411765\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.66611765 0.99611765 0.54188235 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.66611765\n",
      " 0.99611765 0.23129412 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.66611765 0.99611765 0.23129412\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.66611765 1.         0.37494118 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.66611765\n",
      " 0.99611765 0.38270588 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.66611765 0.99611765 0.604\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.66611765 1.         0.604      0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.38270588\n",
      " 0.99611765 0.604      0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01      ]\n"
     ]
    }
   ],
   "source": [
    "scaled_input = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "onodes = 10\n",
    "targets = numpy.zeros(onodes) + 0.01\n",
    "targets[int(all_values[0])] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.special\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.special\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    " \n",
    "#신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화하기\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        #입력, 은닉, 출력 계층의 노드 개수 설정\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        #가중치 행렬 wih와 who -> 정규분포의 중심은 0.0으로 설정, 표준편차는 노드로 들어오는 연결 노드의 개수에 루트를 씌우고 역수를 취함(pow함수)\n",
    "        #배열 내 가중치는 w_i_j로 표기. 노드 i에서 다음 계층의 j로 연결됨을 의미\n",
    "        #w11 w21\n",
    "        #w12 w22 등\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    " \n",
    "        #학습률\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        #활성화 함수는 시그모이드 함수를 이용\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        \n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        #은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        #은닉 계층에서 나가는 신호를 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        #최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # 최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # 오차는 (실제 값 = 계산 값)\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        # 은닉 계층의 오차는 가중치에 의해 나뉜 출력 계층의 오차들을 재조합해 계산\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # 은닉 계층과 출력 계층 간의 가중치 업데이트\n",
    "        self.who += self.lr*numpy.dot((output_errors*final_outputs*(1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        # 입력 계층과 은닉 계층 간의 가중치 업데이트\n",
    "        self.wih += self.lr*numpy.dot((hidden_errors*hidden_outputs*(1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def query(self, inputs_list):\n",
    "        \n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # 은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = numpy.dot(self.wih,inputs)\n",
    "        # 은닉 계층에서 나가는 신호를 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # 최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # 최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "        \n",
    "#입력, 은닉, 출력 노드의 수\n",
    "input_nodes = 784 #손글씨 숫자 이미지를 구성하는 픽셀이 28x28의 크기를 가지기 때문\n",
    "hidden_nodes = 100 #입력 값의 수보다 작은 값을 선택함으로써 신경망이 주요 특징을 찾아낸다, 너무 적은 수의 은닉 계층 노드를 선택한다면 제한적이 될 수도 있다\n",
    "output_nodes = 10 #0~9까지의 레이블을 구분해야 하므로 출력은 10개면 충분하다.\n",
    " \n",
    "#학습률은 0.3으로 정의\n",
    "learning_rate = 0.3\n",
    "#신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)\n",
    " \n",
    "#데이터를 불러오고 그 파일을 읽는다.\n",
    "training_data_file = open(\"C:/Users/hs/Desktop/hand_write/mnist_dataset.csv\",'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "     \n",
    "# 테스트 데이터 모음 내의 모든 레코드 탐색\n",
    "for record in training_data_list:\n",
    "    # 레코드를 쉼표에 의해 분리\n",
    "    all_values = record.split(',')\n",
    "    \n",
    "    # 입력 값의 범위와 값 조정\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # 신경망에 질의\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "    # 가장 높은 값의 인덱스는 레이블의 인덱스와 일치\n",
    "    \n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    \n",
    "    # 정답 또는 오답을 리스트에 추가\n",
    "    \n",
    "    n.train(inputs, targets)\n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "#학습 데이터 모음 내의 모든 레코드 탐색\n",
    "for record in training_data_list:\n",
    "    #레코드를 쉼표에 의해 분리\n",
    "    all_values = record.split(',') #split는 구분자로 사용할 기호를 그 매개변수로 가진다. 리스트를 불러와서 쉼표로 구분하여 분리\n",
    "    #입력 값의 범위와 값 조정\n",
    "    inputs = (numpy.asfarray(all_values[1:])/255.0*0.99)+0.01\n",
    "    #결과 값 생성 (실제 값인 0.99 외에는 모두 0.01)\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "    #all_values[0]은 이 레코드에 대한 결과 값\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs,targets)\n",
    " \n",
    "    pass\n",
    "\n",
    " \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2cfa4ef75e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_file = open(\"C:/Users/hs/Desktop/hand_write/mnist_dataset.csv\")\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    " \n",
    "all_values = test_data_list[0].split(',')\n",
    "print(all_values[0])\n",
    " \n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0477559 ],\n",
       "       [0.10061685],\n",
       "       [0.07054862],\n",
       "       [0.30617516],\n",
       "       [0.00808636],\n",
       "       [0.25369723],\n",
       "       [0.00660738],\n",
       "       [0.00743153],\n",
       "       [0.03497563],\n",
       "       [0.00086795]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((numpy.asfarray(all_values[1:])/255.0*0.99)+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 correct label\n",
      "3 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "5 correct label\n",
      "5 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "9 correct label\n",
      "7 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "5 correct label\n",
      "5 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "5 correct label\n",
      "5 network's answer\n",
      "9 correct label\n",
      "3 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "9 correct label\n",
      "7 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "5 correct label\n",
      "5 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "9 correct label\n",
      "7 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#신경망 테스트\n",
    " \n",
    "#신경망의 성능의 지표가 되는 성적표를 아무 값도 가지지 않도록 초기화\n",
    "scorecard = []\n",
    " \n",
    "#테스트 데이터 모음 내의 모든 레코드 탐색\n",
    "for record in test_data_list:\n",
    "    #레코드를 쉼표에 의해 분리\n",
    "    all_values = record.split(',')\n",
    "    #정답은 첫 번째 값\n",
    "    correct_label = int(all_values[0])\n",
    "    print(correct_label,\"correct label\")\n",
    "    #입력 값의 범위와 값 조정\n",
    "    inputs = (numpy.asfarray(all_values[1:])/255.0*0.99)+0.01\n",
    "    #신경망에 질의\n",
    "    outputs = n.query(inputs)\n",
    "    #가장 높은 값의 인덱스는 레이블의 인덱스와 일치\n",
    "    label = numpy.argmax(outputs)\n",
    "    print(label, \"network's answer\")\n",
    "    #정답 또는 오답을 리스트에 추가\n",
    "    if(label == correct_label):\n",
    "        #정답인 경우 성적표에 1을 더함\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        #정답이 아닌 경우 성적표에 0을 더함\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass\n",
    " \n",
    "print(scorecard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.95\n"
     ]
    }
   ],
   "source": [
    "#스코어 평균\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print(\"performance = \", scorecard_array.sum()/scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    " \n",
    "#신경망 학습시키기\n",
    "for e in range(epochs):\n",
    "    #학습 데이터 모음 내의 모든 레코드 탐색\n",
    "    for record in training_data_list:\n",
    "        #레코드를 쉼표에 의해 분리\n",
    "        all_values = record.split(',') #split는 구분자로 사용할 기호를 그 매개변수로 가진다. 리스트를 불러와서 쉼표로 구분하여 분리\n",
    "        #입력 값의 범위와 값 조정\n",
    "        inputs = (numpy.asfarray(all_values[1:])/255.0*0.99)+0.01\n",
    "        #결과 값 생성 (실제 값인 0.99 외에는 모두 0.01)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        #all_values[0]은 이 레코드에 대한 결과 값\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs,targets)\n",
    " \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 correct label\n",
      "5 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "5 correct label\n",
      "5 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "5 correct label\n",
      "5 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "5 correct label\n",
      "5 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "5 correct label\n",
      "5 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "2 correct label\n",
      "2 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "9 correct label\n",
      "9 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "4 correct label\n",
      "4 network's answer\n",
      "6 correct label\n",
      "6 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "0 correct label\n",
      "0 network's answer\n",
      "7 correct label\n",
      "7 network's answer\n",
      "8 correct label\n",
      "8 network's answer\n",
      "3 correct label\n",
      "3 network's answer\n",
      "1 correct label\n",
      "1 network's answer\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#신경망 테스트\n",
    " \n",
    "#신경망의 성능의 지표가 되는 성적표를 아무 값도 가지지 않도록 초기화\n",
    "scorecard = []\n",
    " \n",
    "#테스트 데이터 모음 내의 모든 레코드 탐색\n",
    "for record in test_data_list:\n",
    "    #레코드를 쉼표에 의해 분리\n",
    "    all_values = record.split(',')\n",
    "    #정답은 첫 번째 값\n",
    "    correct_label = int(all_values[0])\n",
    "    print(correct_label,\"correct label\")\n",
    "    #입력 값의 범위와 값 조정\n",
    "    inputs = (numpy.asfarray(all_values[1:])/255.0*0.99)+0.01\n",
    "    #신경망에 질의\n",
    "    outputs = n.query(inputs)\n",
    "    #가장 높은 값의 인덱스는 레이블의 인덱스와 일치\n",
    "    label = numpy.argmax(outputs)\n",
    "    print(label, \"network's answer\")\n",
    "    #정답 또는 오답을 리스트에 추가\n",
    "    if(label == correct_label):\n",
    "        #정답인 경우 성적표에 1을 더함\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        #정답이 아닌 경우 성적표에 0을 더함\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass\n",
    " \n",
    "print(scorecard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  1.0\n"
     ]
    }
   ],
   "source": [
    "#스코어 평균\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print(\"performance = \", scorecard_array.sum()/scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
